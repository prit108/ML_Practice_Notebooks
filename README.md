# ML_Practice_Notebooks
This is a repository of my jupyter notebooks I wrote while learning ML Algortihms.

1. Linear Regression - A comparative study of iterative gradient descent and normal equations methods to implement the linear regression to fit a linear model to Advertisement Dataset to predict sales given the advertising done in different media.

2. Logistic Regression - Used logistic regression to perform binary classification on the Iris Dataset. Compared the performances of gradient descent and Newton's method on the same dataset.

3. Locally Weighted Linear Regression - Implemented the LWLR in a generic form to allow usage to any dataset. Applied the generic model to House Price Prediction.

4. Naive Bayes - Implemented a generic version of the Naive Bayes model with Laplace Smoothing, compared with ScikitLearn's NB model.

5. Perceptron - Implemented the Perceptron classification algorithm, using the sign function.

6. Support Vector Machine - Implemented Linear and Gaussian SVM and auxiliary functions.
